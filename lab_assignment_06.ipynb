{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Revanthch/INFO-5502/blob/main/lab_assignment_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6MRLBaoVNld"
      },
      "source": [
        "## The sixth Lab-assignment (08/02/2022 11:59'AM' - 08/05/2022 11:59PM, 50 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN1LrSZaVNm5"
      },
      "source": [
        "The purpose of this exercise is to build a simple predicition model which can helpyou understand the workflow of machine learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBJrq1M3VNnA"
      },
      "source": [
        "### Q1 Task Decription (50 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aBxZ78CVNnH"
      },
      "source": [
        "The goal of this assignment is to predict bike share use, given the hour, day, and information about the weather. Companies like Divvy try to predict how much demand there will be for bikes on any given day to allocate resources to redistribute bikes so that, ideally, very few bike stations are ever full (when you can’t park your bike) or empty (when you can’t pick up a bike if you want to).\n",
        "\n",
        "The data (link: https://github.com/suthapalliuday/INFO5502-Summer2022/tree/main/datasets/lab_assignment_06) in Github provides detailed information on the data set and necessary downloads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4fAR_xqVNna"
      },
      "source": [
        "### Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfCAGwdSVNne"
      },
      "source": [
        "You are provided hourly rental data spanning two years (link: https://github.com/suthapalliuday/INFO5502-Summer2022/tree/main/datasets/lab_assignment_06). For this task, the training set is comprised of the first 16 days of each month, while the test set is the 17-19th day of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period. That is, predict \"count\" without using \"count\" or its components \"casual\" and \"registered\".\n",
        "\n",
        "Data Fields\n",
        "\n",
        "datetime - hourly date + timestamp\n",
        "\n",
        "season - 1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
        "\n",
        "holiday - whether the day is considered a holiday\n",
        "\n",
        "workingday - whether the day is neither a weekend nor holiday\n",
        "\n",
        "weather -\n",
        "\n",
        "1 - Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "\n",
        "2 - Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "\n",
        "3 - Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "\n",
        "4 - Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "\n",
        "temp - temperature in Celsius\n",
        "\n",
        "atemp - \"feels like\" temperature in Celsius\n",
        "\n",
        "humidity - relative humidity\n",
        "\n",
        "windspeed - wind speed\n",
        "\n",
        "casual - number of non-registered user rentals initiated\n",
        "\n",
        "registered - number of registered user rentals initiated\n",
        "\n",
        "count - number of total rentals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llbq8UUdVNnq"
      },
      "source": [
        "### Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiF5rj2dVNny"
      },
      "source": [
        "Submission Format\n",
        "\n",
        "Your output (a separate file) must have a header line and should be structured in the following format:\n",
        "\n",
        " datetime,count\n",
        " \n",
        " 2011-01-20 00:00:00,0 \n",
        " \n",
        " 2011-01-20 01:00:00,0\n",
        " \n",
        " 2011-01-20 02:00:00,0\n",
        " \n",
        " ...\n",
        " \n",
        "The tutorial code should demonstrate how to generate such a file from a very simple prediction model. Note, these prediction are to be done on the test file under the data tab, where you do not know the actual count, and should match the rows of the test file in count and order.\n",
        "\n",
        "Your predictions should be compared to the ground truth information (sample_prediction.csv). Score are calculated using Root Mean Squared Error (RMSE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C2BtLsGVNop"
      },
      "source": [
        "### Tips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmamYLV_VNou"
      },
      "source": [
        "●\tAdd features: Pick columns/features from the data you already have. Or make a new feature from the ones you have. For example, the tutorial makes ‘hour’ from the datetime stamp, which seemed very useful. How about ‘month’?\n",
        "\n",
        "●\tModel selection: Try different models. Make sure they are regression models rather than classification models. Tip: random forest regression is a good, all around modeling strategy on complicated data sets.\n",
        "\n",
        "●\tModel tuning: Almost all regression models have parameters to tune (“hyperparameters”). E.g. polynomial regression has the degree of the polynomial (n = 1 for a line, n=2 for a quadratic fit, n=3 for a cubic fit…). Generally, one extreme makes the model too simple (e.g. a line for a curved set of points) and the other extreme makes the model overfit/be too complex, and usually the right choice is in between. For some models it is obvious what to tune (e.g. k for k nearest neighbors regression) and some don’t need much tuning with defaults that often work well. e.g. try changing the number of trees used in the random forest model!\n",
        "\n",
        "●\tCross validation: The tutorial has a simple way of separating training and test data, however, there are better ways of splitting training and test data. Look into cross validation techniques, which are more reliable than an arbitrary split of training and test data.\n",
        "\n",
        "●\tSeparate models for ...: Notice that count comes from just adding casual riders and registered riders. However, what if these two types of riders acted very differently? It might make sense to make two separate models and just add the results of both models together. This is also true for any subsets of your data that may behave wildly differently (e.g. create a separate model for each season?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IotJ8HhzVNo4"
      },
      "source": [
        "### Your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1m-rxqaVNo8"
      },
      "outputs": [],
      "source": [
        "### You code here:\n",
        "import pandas\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_data_frame=pandas.read_csv(\"train_luc.csv\");\n",
        "train_data_frame.describe()\n",
        "\n",
        "def month_of_year(dt):\n",
        "    return datetime.strptime(dt,\"%Y-%m-%d %H:%M:%S\").month\n",
        "\n",
        "def hour_of_day(dt):\n",
        "    return datetime.strptime(dt, \"%Y-%m-%d %H:%M:%S\").time().hour\n",
        "\n",
        "train_data_frame['hour'] = train_data_frame['datetime'].map(hour_of_day)\n",
        "train_data_frame['month'] = train_data_frame['datetime'].map(month_of_year)\n",
        "train_data_frame.head()\n",
        "\n",
        "hours = numpy.unique(train_data_frame['hour'])\n",
        "print(\"hours :\",hours)\n",
        "\n",
        "hours_mean = {}\n",
        "for h in hours:\n",
        "    temp_data = train_data_frame.loc[train_data_frame['hour'] == h]\n",
        "    hours_mean[h] = temp_data['count'].mean()\n",
        "\n",
        "months = numpy.unique(train_data_frame['month'])\n",
        "print(\"months :\", months)\n",
        "\n",
        "months_mean = {}\n",
        "for m in months:\n",
        "    temp_data = train_data_frame.loc[train_data_frame['month'] == m]\n",
        "    months_mean[m] = temp_data['count'].mean()\n",
        "\n",
        "# plot the results hourly, monthly to get an idea. We might see peaks in the rush hours or summer months\n",
        "plt.bar(hours,[hours_mean[h] for h in hours])\n",
        "plt.title(\"Hourly bike usage over 2 years\")\n",
        "plt.ylabel(\"Average number of bikes used\")\n",
        "plt.xlabel(\"hour\")\n",
        "plt.show()\n",
        "plt.bar(months, [months_mean[m] for m in months])\n",
        "plt.title(\"Monthly bike usage over 2 years\")\n",
        "plt.ylabel(\"Average number of bikes used\")\n",
        "plt.xlabel(\"month\")\n",
        "plt.show()\n",
        "\n",
        "# Feature selection - Selecting weather,atemp(feels like), hour, month, season since they can impact bike riding\n",
        "cols = ['hour','month','holiday','workingday','humidity','season','weather','atemp']\n",
        "\n",
        "# Model Selection - using RandomForest regressor\n",
        "model = RandomForestRegressor(n_estimators = 100)\n",
        "\n",
        "print(\"Features selected for later:\",cols)\n",
        "print(\"Model used is : {0}\\n\".format(model))\n",
        "\n",
        "#Model tuning and Cross validation - using KFolds where K=5 which splits data into K-1 folds for training and 1 fold for testing\n",
        "k_fold=KFold(5)\n",
        "counter=1;\n",
        "\n",
        "for result in k_fold.split(train_data_frame):\n",
        "  # converting split datasets into dataframes\n",
        "  new_train= train_data_frame.iloc[result[0]]\n",
        "  new_test = train_data_frame.iloc[result[1]]\n",
        "\n",
        "  y_train=new_train['count']\n",
        "  x_train=new_train[cols]\n",
        "\n",
        "  y_test=new_test['count']\n",
        "  x_test=new_test[cols]\n",
        "\n",
        "  model.fit(x_train, y_train)\n",
        "  print(\"Model Score for Fold {0} is: {1}\".format(counter,model.score(x_train, y_train)))\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "\n",
        "  # squared = False returns RMSE\n",
        "  root_mean_square = mean_squared_error(y_test,y_pred,squared=False)\n",
        "  print(\"Root mean square error for Fold {0} is : {1}\\n\".format(counter,root_mean_square))\n",
        "  counter+=1\n",
        "  test_data_frame = pandas.read_csv('test_luc.csv', header=0)\n",
        "print(\"\\nNumber of samples are :\",test_data_frame.shape[0] ,\". Number of features are:\",test_data_frame.shape[1],\"\\n\")\n",
        "\n",
        "test_data_frame['hour'] = test_data_frame['datetime'].map(hour_of_day)\n",
        "test_data_frame['month'] = test_data_frame['datetime'].map(month_of_year)\n",
        "\n",
        "test_data_frame.head()\n",
        "\n",
        "model.fit(train_data_frame[cols], train_data_frame['count'])\n",
        "pred_count = model.predict(test_data_frame[cols])\n",
        "\n",
        "test_data_frame['count'] = pred_count\n",
        "\n",
        "test_data_frame[['datetime','count']].to_csv('my_prediction.csv', \n",
        "    index=False, header=True)\n",
        "print(\"Predicted the counts and saved as my_prediction.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlMgflSMVNpQ"
      },
      "source": [
        " Question 2 (20 points) Build a regession model to predict the change in price of the stock overtime. It can either be linear regression or non-linear regression. You can download the dataset from here: https://github.com/suthapalliuday/INFO5502-Summer2022/blob/main/datasets/portfolio_data.csv. The implementation of the LSTM on this same dataset was posted here as an reference: https://www.kaggle.com/code/faressayah/stock-market-analysis-prediction-using-lstm/notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMLXje7VNpp"
      },
      "source": [
        " ### Your code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyqWICLzVNpu"
      },
      "outputs": [],
      "source": [
        "### You code here:\n",
        "\n",
        "\n",
        "pred_count = model.predict(test_data_frame[cols])\n",
        "\n",
        "test_data_frame['count'] = pred_count\n",
        "\n",
        "test_data_frame[['datetime','count']].to_csv('my_prediction.csv', \n",
        "    index=False, header=True)\n",
        "print(\"Predicted the counts and saved as my_prediction.csv\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "lab_assignment_06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}